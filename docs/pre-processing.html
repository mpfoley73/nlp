<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.1 Pre-processing | Natural Language Processing in R</title>
  <meta name="description" content="Background and tutorial on natural language processing in R (topic modeling, sentiment analysis) using R." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="2.1 Pre-processing | Natural Language Processing in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Background and tutorial on natural language processing in R (topic modeling, sentiment analysis) using R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 Pre-processing | Natural Language Processing in R" />
  
  <meta name="twitter:description" content="Background and tutorial on natural language processing in R (topic modeling, sentiment analysis) using R." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2023-12-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topicmodeling.html"/>
<link rel="next" href="lda.html"/>
<script src="assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="assets/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="data-prep.html"><a href="data-prep.html"><i class="fa fa-check"></i><b>1</b> Data Preparation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="scrub.html"><a href="scrub.html"><i class="fa fa-check"></i><b>1.1</b> Scrub</a></li>
<li class="chapter" data-level="1.2" data-path="tokenize.html"><a href="tokenize.html"><i class="fa fa-check"></i><b>1.2</b> Tokenize</a></li>
<li class="chapter" data-level="1.3" data-path="spell-check.html"><a href="spell-check.html"><i class="fa fa-check"></i><b>1.3</b> Spell-check</a></li>
<li class="chapter" data-level="1.4" data-path="lemmatize.html"><a href="lemmatize.html"><i class="fa fa-check"></i><b>1.4</b> Lemmatize</a></li>
<li class="chapter" data-level="1.5" data-path="remove-stop-words.html"><a href="remove-stop-words.html"><i class="fa fa-check"></i><b>1.5</b> Remove Stop Words</a></li>
<li class="chapter" data-level="1.6" data-path="prepped-data.html"><a href="prepped-data.html"><i class="fa fa-check"></i><b>1.6</b> Prepped Data</a></li>
<li class="chapter" data-level="1.7" data-path="bigrams.html"><a href="bigrams.html"><i class="fa fa-check"></i><b>1.7</b> Bigrams</a></li>
<li class="chapter" data-level="1.8" data-path="save.html"><a href="save.html"><i class="fa fa-check"></i><b>1.8</b> Save</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="topicmodeling.html"><a href="topicmodeling.html"><i class="fa fa-check"></i><b>2</b> Topic Modeling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="pre-processing.html"><a href="pre-processing.html"><i class="fa fa-check"></i><b>2.1</b> Pre-processing</a></li>
<li class="chapter" data-level="2.2" data-path="lda.html"><a href="lda.html"><i class="fa fa-check"></i><b>2.2</b> LDA</a>
<ul>
<li class="chapter" data-level="" data-path="lda.html"><a href="lda.html#fit"><i class="fa fa-check"></i>Fit</a></li>
<li class="chapter" data-level="" data-path="lda.html"><a href="lda.html#topic-labeling-with-chatgpt"><i class="fa fa-check"></i>Topic Labeling with ChatGPT</a></li>
<li class="chapter" data-level="2.2.1" data-path="lda.html"><a href="lda.html#discussion"><i class="fa fa-check"></i><b>2.2.1</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="lda.html"><a href="lda.html#todo"><i class="fa fa-check"></i>TODO</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="stm.html"><a href="stm.html"><i class="fa fa-check"></i><b>2.3</b> STM</a>
<ul>
<li class="chapter" data-level="" data-path="stm.html"><a href="stm.html#fit-1"><i class="fa fa-check"></i>Fit</a></li>
<li class="chapter" data-level="" data-path="stm.html"><a href="stm.html#interpret"><i class="fa fa-check"></i>Interpret</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>2.4</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentimentanalysis.html"><a href="sentimentanalysis.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="subjectivity-lexicons.html"><a href="subjectivity-lexicons.html"><i class="fa fa-check"></i><b>3.1</b> Subjectivity Lexicons</a></li>
<li class="chapter" data-level="3.2" data-path="polarity-scoring.html"><a href="polarity-scoring.html"><i class="fa fa-check"></i><b>3.2</b> Polarity Scoring</a>
<ul>
<li class="chapter" data-level="" data-path="polarity-scoring.html"><a href="polarity-scoring.html#tidytext"><i class="fa fa-check"></i>tidytext</a></li>
<li class="chapter" data-level="" data-path="polarity-scoring.html"><a href="polarity-scoring.html#sentimentr"><i class="fa fa-check"></i>sentimentr</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="statistical-test.html"><a href="statistical-test.html"><i class="fa fa-check"></i><b>3.3</b> Statistical Test</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Natural Language Processing in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pre-processing" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Pre-processing<a href="pre-processing.html#pre-processing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chapter <a href="data-prep.html#data-prep">1</a> cleaned the text. The next step is to create a document-term matrix (DTM). A DTM has one row per per document, one column per term, and frequencies in the cells. Even with stop words removed, the DTM contains mostly infrequently used terms that would not contribute to topics, so remove its sparse terms. The pre-processing steps are the same for LDA and STM with the exception of the final DTM object class.</p>
<div class="rmdnote">
<p>The LDA and STM model fitting functions in this chapter use different DTM objects. <code>topicmodels::LDA()</code> uses class DocumentTermMatrix from the <strong>tm</strong> package. <code>stm::stm()</code> uses class dfm from the <strong>quanteda</strong> package. DFM stands for document feature matrix. DTM and DFM are essentially the same thing.</p>
</div>
<p>Keep only the decent sized reviews, ones with at least 25 words. If this is a predictive model, now is the time to create a train/test split. Consider weighting the split by the outcome variable of interest, <code>rating</code> in this case, to ensure proportional coverage.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="pre-processing.html#cb8-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb8-2"><a href="pre-processing.html#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="pre-processing.html#cb8-3" tabindex="-1"></a>hotel_gte25 <span class="ot">&lt;-</span> prepped_hotel <span class="sc">%&gt;%</span> <span class="fu">filter</span>(prepped_wrdcnt <span class="sc">&gt;=</span> <span class="dv">25</span>)</span>
<span id="cb8-4"><a href="pre-processing.html#cb8-4" tabindex="-1"></a><span class="fu">nrow</span>(hotel_gte25)</span>
<span id="cb8-5"><a href="pre-processing.html#cb8-5" tabindex="-1"></a><span class="do">## [1] 973</span></span>
<span id="cb8-6"><a href="pre-processing.html#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="pre-processing.html#cb8-7" tabindex="-1"></a><span class="co"># Parameter `strata` ensures proportional coverage of ratings.</span></span>
<span id="cb8-8"><a href="pre-processing.html#cb8-8" tabindex="-1"></a>hotel_split <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(hotel_gte25, <span class="at">prop =</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">4</span>, <span class="at">strata =</span> rating)</span>
<span id="cb8-9"><a href="pre-processing.html#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="pre-processing.html#cb8-10" tabindex="-1"></a>hotel_train <span class="ot">&lt;-</span> <span class="fu">training</span>(hotel_split)</span>
<span id="cb8-11"><a href="pre-processing.html#cb8-11" tabindex="-1"></a><span class="fu">nrow</span>(hotel_train)</span>
<span id="cb8-12"><a href="pre-processing.html#cb8-12" tabindex="-1"></a><span class="do">## [1] 729</span></span>
<span id="cb8-13"><a href="pre-processing.html#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="pre-processing.html#cb8-14" tabindex="-1"></a>hotel_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(hotel_split)</span>
<span id="cb8-15"><a href="pre-processing.html#cb8-15" tabindex="-1"></a><span class="fu">nrow</span>(hotel_test)</span>
<span id="cb8-16"><a href="pre-processing.html#cb8-16" tabindex="-1"></a><span class="do">## [1] 244</span></span>
<span id="cb8-17"><a href="pre-processing.html#cb8-17" tabindex="-1"></a></span>
<span id="cb8-18"><a href="pre-processing.html#cb8-18" tabindex="-1"></a>token_train <span class="ot">&lt;-</span> token <span class="sc">%&gt;%</span> <span class="fu">semi_join</span>(<span class="fu">training</span>(hotel_split), <span class="at">by =</span> <span class="fu">join_by</span>(review_id))</span>
<span id="cb8-19"><a href="pre-processing.html#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="pre-processing.html#cb8-20" tabindex="-1"></a>token_test <span class="ot">&lt;-</span> token <span class="sc">%&gt;%</span> <span class="fu">semi_join</span>(<span class="fu">testing</span>(hotel_split), <span class="at">by =</span> <span class="fu">join_by</span>(review_id))</span></code></pre></div>
<p>Most words add little value to a topic model because they appear infrequently or too frequently. The most common metric for removing sparse terms is the term frequency-inverse document frequency (TF-IDF). TF(t,d) is term <em>t</em>’s usage proportion in document <em>d</em>. IDF(t) is the log of the inverse of the term <em>t</em>’s proportion of documents it appears. For example, “savoy” appears in <em>n</em> = 109 of the <em>N</em> = 729 training documents. Its IDF is log(N/n) = 1.90. “savoy” appears in review #16954 in 2 of 32 (6.25%) of the terms. The TF-IDF score is the product of the two numbers. Here is that prepped review.</p>
<blockquote>
<p>manage night savoy experience superb moment arrive greet experience departure staff fantastic cupcake tea coffee cocktail delicious room expect faultless comfortable breakfast wonderful experience list item breakfast world forward opportunity savoy night</p>
</blockquote>
<p><span class="citation">Nagelkerke (<a href="#ref-Nagelkerke2020b">2020</a>)</span> suggests another route. You already removed the stop words, so the over-used words are out. The TF-IDF approach was developed for long documents. Smaller documents like online reviews have little TF variation (most words are used only once or twice in a review), and the IDF ends up dominating. Instead, just filter on each word’s corpus frequency.</p>
<p>In the end, you need to experiment to find the right cutoff. Using TF-IDF, the elbow in the plot below is around .15. Using that threshold throws out about about 90% of the vocabulary. The corpus frequency plot has an elbow around 4 occurrences. That threshold throws out 80% of the vocabulary.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="pre-processing.html#cb9-1" tabindex="-1"></a>hotel_word_stats <span class="ot">&lt;-</span></span>
<span id="cb9-2"><a href="pre-processing.html#cb9-2" tabindex="-1"></a>  token_train <span class="sc">%&gt;%</span> </span>
<span id="cb9-3"><a href="pre-processing.html#cb9-3" tabindex="-1"></a>  <span class="fu">count</span>(review_id, word, <span class="at">name =</span> <span class="st">&quot;doc_freq&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-4"><a href="pre-processing.html#cb9-4" tabindex="-1"></a>  <span class="fu">bind_tf_idf</span>(word, review_id, doc_freq) <span class="sc">%&gt;%</span></span>
<span id="cb9-5"><a href="pre-processing.html#cb9-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.by =</span> word, <span class="at">corp_freq =</span> <span class="fu">sum</span>(doc_freq)) <span class="sc">%&gt;%</span></span>
<span id="cb9-6"><a href="pre-processing.html#cb9-6" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">corp_pct =</span> corp_freq <span class="sc">/</span> <span class="fu">sum</span>(doc_freq))</span>
<span id="cb9-7"><a href="pre-processing.html#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="pre-processing.html#cb9-8" tabindex="-1"></a>hotel_word_stats <span class="sc">%&gt;%</span> </span>
<span id="cb9-9"><a href="pre-processing.html#cb9-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">tf_idf_bin =</span> <span class="fu">cut</span>(tf_idf, <span class="at">breaks =</span> <span class="dv">50</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb9-10"><a href="pre-processing.html#cb9-10" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">.by =</span> tf_idf_bin, <span class="at">vocab =</span> <span class="fu">n_distinct</span>(word)) <span class="sc">%&gt;%</span></span>
<span id="cb9-11"><a href="pre-processing.html#cb9-11" tabindex="-1"></a>  <span class="fu">arrange</span>(tf_idf_bin) <span class="sc">%&gt;%</span></span>
<span id="cb9-12"><a href="pre-processing.html#cb9-12" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pct =</span> vocab <span class="sc">/</span> <span class="fu">sum</span>(vocab), <span class="at">cumpct =</span> <span class="fu">cumsum</span>(pct)) <span class="sc">%&gt;%</span></span>
<span id="cb9-13"><a href="pre-processing.html#cb9-13" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> tf_idf_bin)) <span class="sc">+</span> </span>
<span id="cb9-14"><a href="pre-processing.html#cb9-14" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="fu">aes</span>(<span class="at">y =</span> pct)) <span class="sc">+</span></span>
<span id="cb9-15"><a href="pre-processing.html#cb9-15" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> cumpct, <span class="at">group =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb9-16"><a href="pre-processing.html#cb9-16" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">13</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb9-17"><a href="pre-processing.html#cb9-17" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;vocabulary&quot;</span>, <span class="at">title =</span> <span class="st">&quot;TF-IDF Method&quot;</span>) <span class="sc">+</span></span>
<span id="cb9-18"><a href="pre-processing.html#cb9-18" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">percent_format</span>(<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb9-19"><a href="pre-processing.html#cb9-19" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">90</span>, <span class="at">vjust =</span> .<span class="dv">5</span>))</span></code></pre></div>
<p><img src="nlp_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="pre-processing.html#cb10-1" tabindex="-1"></a>hotel_word_stats <span class="sc">%&gt;%</span> </span>
<span id="cb10-2"><a href="pre-processing.html#cb10-2" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb10-3"><a href="pre-processing.html#cb10-3" tabindex="-1"></a>    <span class="at">corp_freq_bin =</span> <span class="fu">if_else</span>(corp_freq <span class="sc">&gt;</span> <span class="dv">19</span>, <span class="st">&quot;20+&quot;</span>, <span class="fu">as.character</span>(corp_freq)),</span>
<span id="cb10-4"><a href="pre-processing.html#cb10-4" tabindex="-1"></a>    <span class="at">corp_freq_bin =</span> <span class="fu">factor</span>(corp_freq_bin, <span class="at">levels =</span> <span class="fu">c</span>(<span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">19</span>), <span class="st">&quot;20+&quot;</span>))</span>
<span id="cb10-5"><a href="pre-processing.html#cb10-5" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="pre-processing.html#cb10-6" tabindex="-1"></a>  <span class="co"># mutate(corp_pct_bin = cut(corp_pct, breaks = 100)) %&gt;%</span></span>
<span id="cb10-7"><a href="pre-processing.html#cb10-7" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">.by =</span> corp_freq_bin, <span class="at">vocab =</span> <span class="fu">n_distinct</span>(word)) <span class="sc">%&gt;%</span></span>
<span id="cb10-8"><a href="pre-processing.html#cb10-8" tabindex="-1"></a>  <span class="fu">arrange</span>(corp_freq_bin) <span class="sc">%&gt;%</span></span>
<span id="cb10-9"><a href="pre-processing.html#cb10-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pct =</span> vocab <span class="sc">/</span> <span class="fu">sum</span>(vocab), <span class="at">cumpct =</span> <span class="fu">cumsum</span>(pct)) <span class="sc">%&gt;%</span></span>
<span id="cb10-10"><a href="pre-processing.html#cb10-10" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> corp_freq_bin, <span class="at">y =</span> cumpct)) <span class="sc">+</span> </span>
<span id="cb10-11"><a href="pre-processing.html#cb10-11" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="fu">aes</span>(<span class="at">y =</span> pct)) <span class="sc">+</span></span>
<span id="cb10-12"><a href="pre-processing.html#cb10-12" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> cumpct, <span class="at">group =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb10-13"><a href="pre-processing.html#cb10-13" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">4</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-14"><a href="pre-processing.html#cb10-14" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;vocabulary&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Corpus Frequency Method&quot;</span>) <span class="sc">+</span></span>
<span id="cb10-15"><a href="pre-processing.html#cb10-15" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">percent_format</span>(<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb10-16"><a href="pre-processing.html#cb10-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">90</span>, <span class="at">vjust =</span> .<span class="dv">5</span>))</span></code></pre></div>
<p><img src="nlp_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<p>Compare the resulting DTMs. The TF-IDF method keeps half the documents and 1,500 terms. The corpus frequency method retains <em>all</em> documents while limiting the vocabulary to 1,200 terms. Corpus frequency does seem superior.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="pre-processing.html#cb11-1" tabindex="-1"></a>(dtm_tfidf <span class="ot">&lt;-</span></span>
<span id="cb11-2"><a href="pre-processing.html#cb11-2" tabindex="-1"></a>  hotel_word_stats <span class="sc">%&gt;%</span></span>
<span id="cb11-3"><a href="pre-processing.html#cb11-3" tabindex="-1"></a>  <span class="fu">filter</span>(tf_idf <span class="sc">&gt;</span> .<span class="dv">15</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-4"><a href="pre-processing.html#cb11-4" tabindex="-1"></a>  <span class="fu">cast_dtm</span>(<span class="at">document =</span> review_id, <span class="at">term =</span> word, <span class="at">value =</span> doc_freq))</span>
<span id="cb11-5"><a href="pre-processing.html#cb11-5" tabindex="-1"></a><span class="do">## &lt;&lt;DocumentTermMatrix (documents: 426, terms: 1560)&gt;&gt;</span></span>
<span id="cb11-6"><a href="pre-processing.html#cb11-6" tabindex="-1"></a><span class="do">## Non-/sparse entries: 1754/662806</span></span>
<span id="cb11-7"><a href="pre-processing.html#cb11-7" tabindex="-1"></a><span class="do">## Sparsity           : 100%</span></span>
<span id="cb11-8"><a href="pre-processing.html#cb11-8" tabindex="-1"></a><span class="do">## Maximal term length: 26</span></span>
<span id="cb11-9"><a href="pre-processing.html#cb11-9" tabindex="-1"></a><span class="do">## Weighting          : term frequency (tf)</span></span>
<span id="cb11-10"><a href="pre-processing.html#cb11-10" tabindex="-1"></a></span>
<span id="cb11-11"><a href="pre-processing.html#cb11-11" tabindex="-1"></a>(dtm_corpfreq <span class="ot">&lt;-</span></span>
<span id="cb11-12"><a href="pre-processing.html#cb11-12" tabindex="-1"></a>  hotel_word_stats <span class="sc">%&gt;%</span></span>
<span id="cb11-13"><a href="pre-processing.html#cb11-13" tabindex="-1"></a>  <span class="fu">filter</span>(corp_freq <span class="sc">&gt;</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-14"><a href="pre-processing.html#cb11-14" tabindex="-1"></a>  <span class="fu">cast_dtm</span>(<span class="at">document =</span> review_id, <span class="at">term =</span> word, <span class="at">value =</span> doc_freq))</span>
<span id="cb11-15"><a href="pre-processing.html#cb11-15" tabindex="-1"></a><span class="do">## &lt;&lt;DocumentTermMatrix (documents: 729, terms: 1211)&gt;&gt;</span></span>
<span id="cb11-16"><a href="pre-processing.html#cb11-16" tabindex="-1"></a><span class="do">## Non-/sparse entries: 31208/851611</span></span>
<span id="cb11-17"><a href="pre-processing.html#cb11-17" tabindex="-1"></a><span class="do">## Sparsity           : 96%</span></span>
<span id="cb11-18"><a href="pre-processing.html#cb11-18" tabindex="-1"></a><span class="do">## Maximal term length: 14</span></span>
<span id="cb11-19"><a href="pre-processing.html#cb11-19" tabindex="-1"></a><span class="do">## Weighting          : term frequency (tf)</span></span></code></pre></div>
<p>The pre-processing step sure pares down the corpus. The high frequency terms comprise only 20% of the vocabulary, but are still 83% of the total word usage.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="pre-processing.html#cb12-1" tabindex="-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb12-2"><a href="pre-processing.html#cb12-2" tabindex="-1"></a>  <span class="st">`</span><span class="at">high freq words</span><span class="st">`</span> <span class="ot">=</span> hotel_word_stats <span class="sc">%&gt;%</span> <span class="fu">filter</span>(corp_freq <span class="sc">&gt;</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-3"><a href="pre-processing.html#cb12-3" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">distinct_words =</span> <span class="fu">n_distinct</span>(word), <span class="at">total_words =</span> <span class="fu">sum</span>(doc_freq)),</span>
<span id="cb12-4"><a href="pre-processing.html#cb12-4" tabindex="-1"></a>  <span class="st">`</span><span class="at">low freq words</span><span class="st">`</span> <span class="ot">=</span> hotel_word_stats <span class="sc">%&gt;%</span> <span class="fu">filter</span>(corp_freq <span class="sc">&lt;=</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-5"><a href="pre-processing.html#cb12-5" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">distinct_words =</span> <span class="fu">n_distinct</span>(word), <span class="at">total_words =</span> <span class="fu">sum</span>(doc_freq)),</span>
<span id="cb12-6"><a href="pre-processing.html#cb12-6" tabindex="-1"></a>  <span class="at">.id =</span> <span class="st">&quot;partition&quot;</span></span>
<span id="cb12-7"><a href="pre-processing.html#cb12-7" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb12-8"><a href="pre-processing.html#cb12-8" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">total_pct =</span> total_words <span class="sc">/</span> <span class="fu">sum</span>(total_words) <span class="sc">*</span> <span class="dv">100</span>, </span>
<span id="cb12-9"><a href="pre-processing.html#cb12-9" tabindex="-1"></a>         <span class="at">distinct_pct =</span> distinct_words <span class="sc">/</span> <span class="fu">sum</span>(distinct_words) <span class="sc">*</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-10"><a href="pre-processing.html#cb12-10" tabindex="-1"></a>  <span class="fu">select</span>(partition, distinct_words, distinct_pct, total_words, total_pct) <span class="sc">%&gt;%</span></span>
<span id="cb12-11"><a href="pre-processing.html#cb12-11" tabindex="-1"></a>  janitor<span class="sc">::</span><span class="fu">adorn_totals</span>()</span></code></pre></div>
<pre><code>##        partition distinct_words distinct_pct total_words total_pct
##  high freq words           1211     20.41126       38093  83.15252
##   low freq words           4722     79.58874        7718  16.84748
##            Total           5933    100.00000       45811 100.00000</code></pre>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Nagelkerke2020b" class="csl-entry">
Nagelkerke, Jurriaan. 2020. <span>“NLP with r Part 1: Topic Modeling to Identify Topics in Restaurant Reviews,”</span> November. <a href="https://medium.com/cmotions/nlp-with-r-part-1-topic-modeling-to-identify-topics-in-restaurant-reviews-3ee870e6cd8">https://medium.com/cmotions/nlp-with-r-part-1-topic-modeling-to-identify-topics-in-restaurant-reviews-3ee870e6cd8</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topicmodeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lda.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
