[["index.html", "Natural Language Processing in R Intro", " Natural Language Processing in R Michael Foley 2023-11-10 Intro These notes consolidate several resources I’ve encountered while working on text mining projects: Text Mining with R (Silge and Robinson 2017) Introduction to Natural Language Processing in R (DataCamp) Topic Modeling in R (DataCamp) Introduction to Text Analysis in R” (DataCamp) String Manipulation in R with stringr (DataCamp) Text Mining with Bag-of-Words in R (DataCamp) Sentiment Analysis in R (DataCamp) Tidy Sentiment Analysis in R (DataCamp) Julia Silge’s The game is afoot! Topic modeling of Sherlock Holmes stories Julia Silge’s Training, evaluating, and interpreting topic models Toward understanding 17th century English culture: A structural topic model of Francis Bacon’s ideas References "],["data-preparation.html", "Chapter 1 Data Preparation", " Chapter 1 Data Preparation This section covers how to prepare a corpus for text analysis. I’ll work with the customer reviews of London-based hotels data set hosted on data.world. hotel_raw contains 27K reviews of the ten most- and ten least-expensive hotels in London. The csv file is located online here. I saved it to my \\inputs directory. library(tidyverse) library(tidytext) library(scales) library(glue) hotel_0 &lt;- read_csv( &quot;input/london_hotel_reviews.csv&quot;, col_types = &quot;cicccc&quot;, col_names = c(&quot;property&quot;, &quot;rating&quot;, &quot;title&quot;, &quot;review&quot;, &quot;reviewer_loc&quot;, &quot;review_dt&quot;), skip = 1 ) %&gt;% mutate(review_id = row_number()) %&gt;% select(review_id, everything()) glimpse(hotel_0) ## Rows: 27,330 ## Columns: 7 ## $ review_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ property &lt;chr&gt; &quot;Apex London Wall Hotel&quot;, &quot;Corinthia Hotel London&quot;, &quot;The … ## $ rating &lt;int&gt; 5, 5, 5, 4, 5, 1, 5, 5, 5, 5, 5, 4, 2, 4, 5, 5, 5, 5, 5, … ## $ title &lt;chr&gt; &quot;Ottima qualit\\xe0 prezzo&quot;, &quot;By far, my best hotel in the… ## $ review &lt;chr&gt; &quot;Siamo stati a Londra per un week end ed abbiamo alloggia… ## $ reviewer_loc &lt;chr&gt; &quot;Casale Monferrato, Italy&quot;, &quot;Savannah, Georgia&quot;, &quot;London&quot;… ## $ review_dt &lt;chr&gt; &quot;10/20/2012&quot;, &quot;3/23/2016&quot;, &quot;7/30/2013&quot;, &quot;6/2/2012&quot;, &quot;11/2… "],["scrub.html", "1.1 Scrub", " 1.1 Scrub The data needs cleaning. I’ll follow some of the techniques used by Nagelkerke (2020). One issue is tags like &lt;e9&gt; and unicode characters like &lt;U+0440&gt;. One way to get rid of unicode characters is to convert them to ASCII tags with iconv() and then remove the ASCII tags with str_remove(). E.g., iconv() converts &lt;U+0093&gt; to &lt;93&gt; which you can remove with regex \"\\\\&lt;[:alnum]+\\\\&gt;]\".1 There are also some reviews in other languages that I’ll just drop. And some hotel names are pretty long, so I’ll abbreviate them. hotel_1 &lt;- hotel_0 %&gt;% mutate( review = iconv(review, from = &quot;&quot;, to = &quot;ASCII&quot;, sub = &quot;byte&quot;), # Remove &lt;..&gt; review = str_remove_all(review, &quot;\\\\&lt;[[:alnum:]]+\\\\&gt;&quot;), # Remove &lt;U+####&gt; review = str_remove_all(review, &quot;\\\\&lt;U\\\\+[:alnum:]{4}\\\\&gt;&quot;), # Shorten some of the hotel names. property = factor(str_remove_all( property, &quot;( - .*)|(, .*)|( Hotel)|( London)|(The )|( at .*)|( Hyde .*)|( Knights.*)&quot; )), # Interesting metadata review_chrs = str_length(review) ) %&gt;% # Exclude reviews written in a foreign language. One heuristic to handle this # is to look for words common in other languages that do not also occur in English. filter( !str_detect(review, &quot;( das )|( der )|( und )|( en )&quot;), # German !str_detect(review, &quot;( et )|( de )|( le )|( les )&quot;), # French !str_detect(review, &quot;( di )|( e )|( la )&quot;), # Italian !str_detect(review, &quot;( un )|( y )&quot;), # Spanish str_length(review) &gt; 0 ) # x &lt;- hotel_0 %&gt;% filter(review_id == 175) %&gt;% pull(review) # str_remove_all(x, &quot;\\\\&lt;U\\\\+[:alnum:]{4}\\\\&gt;&quot;) # hotel_1 %&gt;% filter(review_id == 175) # hotel_0 %&gt;% inner_join(hotel_1, by = &quot;review_id&quot;) %&gt;% filter(review.x != review.y) That might be enough. Let’s explore the data. # 90% of reviews rate the property a 4 or 5. hotel_1 %&gt;% janitor::tabyl(rating) ## rating n percent ## 1 498 0.02096401 ## 2 587 0.02471059 ## 3 1379 0.05805094 ## 4 4860 0.20458851 ## 5 16431 0.69168596 # Some reviews are as small as 16 characters, but they can get quite large. hotel_1 %&gt;% pull(review_chrs) %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 307.5 514.0 714.0 870.0 30734.0 # A few reviews hotel_1 %&gt;% sample_n(3, seed = 12345) %&gt;% select(review_chrs, review) %&gt;% flextable::flextable() %&gt;% flextable::valign(j = 1, valign = &quot;top&quot;) %&gt;% flextable::autofit() .cl-05139ca2{}.cl-050c5442{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-050c5456{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-050f30b8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-050f30c2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-050f30cc{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-050f43f0{width:1.088in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f43fa{width:65.716in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f43fb{width:1.088in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f4404{width:65.716in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f4405{width:1.088in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f440e{width:65.716in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f440f{width:1.088in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-050f4418{width:65.716in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}review_chrsreview1,060The high tea comprises finger sandwiches &amp;amp; scones (refillable), asparagus &amp;amp; egg with hollandaise sauce, a slice of cake, glass of champagne &amp;amp; tea of course. The other tea option replaces the asparagus with a selection of pastries. | Comparing the Savoy and Claridges | Ambience: Savoy is grander and has a larger dining room. Both have live music | Service: Both excellent, but Claridges seemed a bit warmer and more genuine | Scones: Claridges wins. The scones at Savoy were served not as warm, larger but not as flavourful, the cream/jam did not come in individual portions for each diner. The marco polo gelee at Claridges is more aromatic and finer than Savoy which serves a good but not remarkable strawberry jam. The clotted cream at both hotels were to me identical. But overall I was not blown away by Savoy's scones. | Sandwiches: Claridges wins. The sandwich filling is thicker, more even, and tastier fillings. | Overall, Savoy is good but Claridges has that extra attention to detail in their scones and sandwiches that makes it better.230We have had just had the most amazing time ever at this restaurant. Our host Greta was the most amazing lady ever, Greta looked after us so well and made our day,we love her the food was A* and couldnt b faulted at all :-) x x x x242Went here for afternoon tea whilst we were in London for the weekend for my mum's birthday. It was very reasonably priced, lots and lots of delicious sandwiches and cakes and a never ending supply of tea! A great venue for a special occasion. Nagelkerke (2020) recommends removing punctuation to focus on the entire text rather than the sentences within. Nagelkerke also suggests removing very short (&lt;= 3 chars) for anything other than sentiment analysis. I’m going to keep punctuation and short reviews for now. References "],["tokenize.html", "1.2 Tokenize", " 1.2 Tokenize Tokenize the reviews. Even if you want bigrams, it is often helpful to tokenize into unigrams first to clean and regularize. token_0 &lt;- hotel_1 %&gt;% select(review_id, review) %&gt;% unnest_tokens(&quot;word&quot;, review) # Reviews range from 1-5,712 words. token_0 %&gt;% count(review_id) %&gt;% pull(n) %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 55.0 92.0 129.6 158.0 5712.0 Some reviews are as short as three words and as long as 7,938(!) words. Nagelkerke (2020) recommends discarding reviews with few (&lt;=50) tokens on the grounds that short reviews will not add much in terms of different topics within reviews.2. That’s about 25% of this sample. I’ll leave them in for now. References "],["spell-check.html", "1.3 Spell-check", " 1.3 Spell-check Run a spell-check to regularize the data. Its possible to land on the wrong correction, but there is probably more to gain than lose. Only a very small fraction of the tokens were misspellings. # There are multiple possible right spellings, so just choose one. spell_check &lt;- fuzzyjoin::misspellings %&gt;% distinct(misspelling, .keep_all = TRUE) token_1 &lt;- token_0 %&gt;% left_join(spell_check, by = join_by(word == misspelling)) %&gt;% mutate(word = coalesce(correct, word)) %&gt;% select(-correct) # Only .08% of words were misspelled. mean(token_0$word != token_1$word) ## [1] 0.000930987 # Examples. tibble(before = token_0$word, after = token_1$word) %&gt;% filter(before != after) %&gt;% head() ## # A tibble: 6 × 2 ## before after ## &lt;chr&gt; &lt;chr&gt; ## 1 resturant restaurant ## 2 excellance excellence ## 3 reccomend recommend ## 4 reccommend recommend ## 5 accomodating accommodating ## 6 ther there "],["lemmatize.html", "1.4 Lemmatize", " 1.4 Lemmatize Stemming and lemmatizing are ways to convert word variations like “staying”, “stayed”, and “stay” into a generic form: “stay”. Stemming tends to chop off endings to create a root word, but the stem is often not a word itself. E.g., “staying” becomes “stai”. Lemmatize gives you the more natural “stay”. token_2 &lt;- token_1 %&gt;% mutate(word = textstem::lemmatize_words(word)) # Examples. tibble(before = token_1$word, after = token_2$word) %&gt;% filter(before != after) %&gt;% head() ## # A tibble: 6 × 2 ## before after ## &lt;chr&gt; &lt;chr&gt; ## 1 had have ## 2 staying stay ## 3 nights night ## 4 was be ## 5 staying stay ## 6 was be "],["remove-stop-words.html", "1.5 Remove Stop Words", " 1.5 Remove Stop Words Stop words usually add no value, but you should pay attention to what you are dropping. Be ready to add pertinent words back and perhaps drop others. # Start with a standard list. stop &lt;- tidytext::stop_words %&gt;% # Don&#39;t remove potentially useful words. filter(!word %in% c(&quot;appreciate&quot;, &quot;room&quot;)) %&gt;% # But also exclude these words. bind_rows(tibble(word = as.character(0:9))) token_3 &lt;- token_2 %&gt;% anti_join(stop, by = &quot;word&quot;) # Most frequently removed words token_2 %&gt;% semi_join(stop, by = &quot;word&quot;) %&gt;% count(word, sort = TRUE) ## # A tibble: 523 × 2 ## word n ## &lt;chr&gt; &lt;int&gt; ## 1 the 196448 ## 2 be 162699 ## 3 and 117632 ## 4 a 98229 ## 5 to 78025 ## 6 in 54402 ## 7 we 47724 ## 8 of 44775 ## 9 i 43744 ## 10 have 40066 ## # ℹ 513 more rows # A typical review, before and after bind_cols( review_id = 2:4, before = hotel_1 %&gt;% filter(review_id %in% 2:4) %&gt;% pull(review), after = token_3 %&gt;% filter(review_id %in% 2:4) %&gt;% summarize(.by = review_id, x = paste(word, collapse = &quot; &quot;)) %&gt;% pull(x) ) %&gt;% flextable::flextable() %&gt;% flextable::valign(valign = &quot;top&quot;) %&gt;% flextable::autofit() .cl-07bb3cc6{}.cl-07b4aa3c{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-07b4aa46{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-07b72744{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-07b72758{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-07b72759{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-07b72762{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-07b73572{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73573{width:87.36in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b7357c{width:44.019in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b7357d{width:0.918in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73586{width:87.36in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73587{width:44.019in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73590{width:0.918in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73591{width:87.36in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b73592{width:44.019in;background-color:transparent;vertical-align: top;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b7359a{width:0.918in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b7359b{width:87.36in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-07b735a4{width:44.019in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}review_idbeforeafter2I had a pleasure of staying in this hotel for 7 nights recently. This hotel was perfect in every way. Communication with the hotel before staying was prompt, and very efficient. Checking in was a breeze. You go through the spectacular lobby with modern glass chandeliers and take the elevator to your room. My room, they gave me an upgrade to junior suite, was spectacular. We had a walk-in closet of the size where you could have put a small bed in there; it served us nicely for the seven day stay. The decor was very refined, and oh the bathroom! Carrera marble floor was heated throughout, rain shower was to die for! | Location, as it turned out, was as good as it can be. We were 5 minutes walk to Trafalgar Square, but it was very quiet. Right outside was Embankment tube stop. We would walk to theater area and to numerous restaurants, and many major sites, such as London Eye or Westminster Abbey were within walking distance. | We had buffet breakfast or room service every morning. It was pricy, but my rate included it. Couple of nights, we had glass of wine sitting in front of fire place in the lobby. I used the spa, which is included in the room rate, almost every night. After a windchill day of sightseeing, the steam sauna and jacuzzi would soften my weary muscles. | I have stayed in many 5 star hotels around the world, but this hotel tops it. I would return here in a heartbeat next time I am in London.pleasure stay hotel night recently hotel perfect communication hotel stay prompt efficient check breeze spectacular lobby modern glass chandelier elevator room room upgrade junior suite spectacular walk closet size bed serve nicely day stay decor refine bathroom carrera marble floor heat rain shower die location minute walk trafalgar square quiet embankment tube stop walk theater numerous restaurant major site london eye westminster abbey walk distance buffet breakfast room service morning pricy rate include couple night glass wine sit front fire lobby spa include room rate night windchill day sightsee steam sauna jacuzzi soften weary muscle stay star hotel world hotel top return heartbeat time london3A very lovely first visit to this iconic hotel bar! | Wonderful service, without being intrusive at all! Very delicious cocktails and just generally all round, a very indulgent experience. | Well worth visiting only for that 'once in a lifetime' experience, though do make sure you are feeling 'flush' it doesn't come cheap!lovely visit iconic hotel bar wonderful service intrusive delicious cocktail round indulgent experience worth visit lifetime experience feel flush cheap43 of us stayed at the Rhodes Hotel for 4 nights, its a great location for taking the Paddington Express from Heathrow. We like the location clost to the partk and in walking distance of most locations. The room and bath were small compared to American Hotels but very clean. We enjoyed the free WIFI. The owners and the staff were very friendly and helpful with taxi's and resturant recomendations. We would stay there again.stay rhodes hotel night location paddington express heathrow location clost partk walk distance location room bath compare american hotel clean enjoy free wifi owner staff friendly helpful taxi's restaurant recomendations stay At this point, you might decide to throw out smaller reviews because they are unlikely to identify multiple topics (Gils 2020). References "],["bigrams.html", "1.6 Bigrams", " 1.6 Bigrams I don’t want bigrams where one or both tokens are stop words, but on the other hand, I don’t want to construct bigrams after removing the stop words either since they are not actually in the text. token_2 had spell-checked and lemmatized tokens, but stop words still present. Reconstruct the reviews, then tokenize to bigrams. bigrams_0 &lt;- token_2 %&gt;% summarize(.by = review_id, reconstructed = paste(word, collapse = &quot; &quot;)) %&gt;% unnest_tokens(&quot;bigram&quot;, reconstructed, token = &quot;ngrams&quot;, n = 2) # Remove the bigrams where one or both words are stop words bigrams_1 &lt;- bigrams_0 %&gt;% separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% anti_join(stop, by = join_by(word1 == word)) %&gt;% anti_join(stop, by = join_by(word2 == word)) %&gt;% mutate(bigram = paste(word1, word2, collapse = &quot; &quot;)) %&gt;% select(review_id, bigram) "],["further-reading.html", "1.7 Further Reading", " 1.7 Further Reading These notes are heavily indebted to this series of articles from Nagelkerke NLP with R part 0: Preparing Review Data for NLP and Predictive Modeling "],["topicmodeling.html", "Chapter 2 Topic Modeling", " Chapter 2 Topic Modeling These notes are primarily compiled from the vignette for the STM package. Topic models are unsupervised ML models that identify topics as clusters of words with an associated probability distribution, and a probability distribution of topics within each document. There are two commonly used models: LDA and STM. LDA is the simpler model and is implemented in the popular topicmodels package. STM incorporates document metadata into the model. It is implemented in the STM package. These notes also discuss CTM, also in topicmodels, that is somewhere between LDA and STM. I discuss CTM because it is a bridge from LDA to STM. All three topic models are generative models of word counts. That means they assume there is some process that generates text which is a mixture of topics composed of words which occur with varying probabilities. Think of the observed text document as the product of an algorithm that selected each word in two stages: 1) it sampled a topic from a probability distribution, then 2) it sampled a word from the topic’s word probability distribution. The object in topic modeling is to tune the hyperparameters that define those probability distributions. In a way, topic models do the opposite of what you might expect. They are not estimating the probability that each document is one of those topics. They assume all topics contribute to each document and instead estimate their relative contributions. More concisely, the models treat documents as a mixture of topics, and the topics as a mixture of words where each word has a probability of belonging to each topic. The sum of topic proportions in document is one; the sum of word probabilities in a topic is one. This leads to two frameworks for thinking about topics. A topic’s prevalance in a document measures the proportion of the document generated by it. The topic’s content is the probability distribution of words associated with it. What distinguishes the following following models is how they handle these frameworks. An STM model defines covariates associated with prevalence and content; CTM does not. I don’t think LDA does either. We’re kind of at the limit of my understanding here. "],["learning-by-example.html", "2.1 Learning by Example", " 2.1 Learning by Example I will work through the model concepts by example using the stm::gadarian data set. This data set has n = 351 comments about immigration in an experimental setting. The test group as specifically instructred to write about what made them anxious about immigration. There is also a variable pid_rep for political party. gadarian_dat &lt;- stm::gadarian %&gt;% rename(comment = open.ended.response) %&gt;% select(-MetaID) glimpse(gadarian_dat) ## Rows: 341 ## Columns: 3 ## $ treatment &lt;dbl&gt; 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, … ## $ pid_rep &lt;dbl&gt; 1.00000, 1.00000, 0.33300, 0.50000, 0.66667, 0.00000, 0.8330… ## $ comment &lt;chr&gt; &quot;problems caused by the influx of illegal immigrants who are… "],["lda.html", "2.2 LDA", " 2.2 LDA Latent Dirichlet allocation (LDA) is an instance of a general family of mixed membership models that decompose data into latent components. Latent refers to unidentified topics and Dirichlet refers to the type of distribution followed by the words in the the topics and by the topics in the documents. Algorithm LDA assumes each document is created by a generative process where topics are included according to probabilities and words are included in the topics according to probabilities. The LDA algorithm determines what those probabilities are. The algorithm is: For each document \\(d_i\\), randomly assign each word to one of the K topics. Note that each \\(w_j\\) may be assigned to a different topic in each documents. For each document, tabulate the number of words in each topic, a \\(d \\times K\\) matrix. For each word, tabulate the sum of occurrences across all documents, a \\(w \\times K\\) matrix. Resample a single instance of a word from the corpus and remove it from the analysis, decrementing the document’s topic count and the word’s topic count. Calculate the gamma matrix, \\(\\gamma\\), and the beta matrix, \\(\\beta\\). the gamma matrix is the probability distribution of topics for each document, \\[p(t_k|d_i) = \\frac{n_{ik} + \\alpha}{N_i + K \\alpha}\\] were \\(n_{ik}\\) is the number of words in document \\(i\\) for topic \\(k\\), \\(N_i\\) is the total number of words in \\(i\\), and \\(\\alpha\\) is a hyperparameter. For each \\(d_i\\), \\(\\sum_{k \\in K} \\gamma_{ik} = 1\\). the beta matrix is the probability distribution of words for each topic, \\[p(w_j|t_k) = \\frac{m_{j,k} + \\beta}{\\sum_{j \\in V}m_{j,k} + V\\beta}\\] where \\(m_{j,k}\\) is the corpus-wide frequency count of word \\(w_j\\) to topic \\(k\\), \\(V\\) is the number of distinct words in the corpus, and \\(\\beta\\) is a hyperparameter. For each \\(t_k\\), \\(\\sum_{j \\in V} \\beta_{kj} = 1\\). Perform Gibbs sampling. Calculate the joint probability distribution of words for each document and topic, \\(p(w_j|t_k,d_i) = p(t_k|d_i)p(w_j|t_k)\\). Assign each word, \\(w_j\\), to the topic with the maximum joint probability. Repeat steps 3-6 for all of the words in all of the documents. Repeat steps 3-7 for a pre-determined number of iterations. LDA thus has 3 hyperparameters: document-topic density factor, \\(\\alpha\\), topic-word density factor, \\(\\beta\\), and topic count, \\(K\\). \\(\\alpha\\) controls the number of topics expected per document (large \\(\\alpha\\) = more topics). \\(\\beta\\) controls the distribution of words per topic (large \\(\\beta\\) = more words). Ideally, you want a few topics per document and a few words per topics, so, \\(\\alpha\\) and \\(\\beta\\) are typically set below one. \\(K\\) is set using a combination of domain knowledge, coherence, and exclusivity. Evaluation Held-out Likelihood (discussion of hold-out probability) (Wallach et al., 2009). Semantic Coherence Exclusivity Generally, the greater the number of topics in a model, the lower the quality of the smallest topics. One way around this is simply hiding the low-quality topics. The coherence measure (Mimno et al. 2011) evaluates topics. References "],["ctm.html", "2.3 CTM", " 2.3 CTM The Correlated Topic Model (CTM) (Blei and Lafferty 2007) builds on the LDA model (chapter 2.2). References "],["stm.html", "2.4 STM", " 2.4 STM STM incorporates arbitrary document metadata into the topic model. Without the inclusion of covariates, STM reduces to a logistic-normal topic model, often called the Correlated Topic Model (CTM) (chapter 2.3). The goal of STM is to discover topics and estimate their relationship to the metadata. Data Preparation The stm package represents a text corpus as an object with three components: a sparse matrix of counts by document and vocabulary word vector index, the vocabulary word vector, and document metadata. stm::textProcessor() is essentially a wrapper around the tm package. It: * converts words to lowercase, * removes stop words (including custom stop words!), numbers, and punctuation, and * stems words. After processing, stm::prepDocuments() removes infrequently appearing words, and removes any documents that contain no words after processing and removing words. gadarian_processed &lt;- textProcessor(gadarian_dat$comment, metadata = gadarian_dat) ## Building corpus... ## Converting to Lower Case... ## Removing punctuation... ## Removing stopwords... ## Removing numbers... ## Stemming... ## Creating Output... plotRemoved(gadarian_processed$documents, lower.thresh = seq(10, 200, by = 10)) Prepare Evaluate Interpret Visualize "],["data-formats.html", "2.5 Data Formats", " 2.5 Data Formats There are five common text mining packages, each with their own format requirements. Whichever package you work in, there is a decent chance you will want to use a function from one of the others, so you need some fluency in them all. tm works with Corpus objects (raw text with document and corpus metadata). Many tm algorithms work with a document-term matrix (DTM), a sparse matrix with one row per document, one column per term, and values equaling the word count or tf-idf. quanteda also works with Corpus objects, but has its own implementation. Many quanteda algorithms work with a document-feature matrix (DFM), again similar to tm’s DTM. tidytext works with tibbles. Many tidytext algorithms work with tibbles with one row per token (usually a word, but possibly a large item of text), a frequency count column, and possibly other metadata columns. qdap works with text fields in a data frame, so it does not require any particular data structure. sentimentr is similar to qdap. Let’s take the sawyer_raw data frame and pre-process it for all three packages. tm Turn the character vector sawyer_raw$text into a text source with VectorSource(), then turn the text source into a corpus with vCorpus(). Clean the corpus with a series of utility functions. One particularly important function, removeWords(), removes stop words, plus any custom stop words. I would normally add “tom” because it is so ubiquitous throughout the text. However, in this case I won’t because stopwords includes valence shifting words like “very” which are used in polarity scoring. I can remove them later for other exercises. # (sawyer_tm &lt;- VCorpus(VectorSource(sawyer$text)) %&gt;% # tm_map(content_transformer(replace_abbreviation)) %&gt;% # tm_map(removePunctuation) %&gt;% # tm_map(removeNumbers) %&gt;% # tm_map(content_transformer(tolower)) %&gt;% # tm_map(removeWords, c(stopwords(&quot;en&quot;), &quot;tom&quot;)) %&gt;% # tm_map(stripWhitespace)) Each document in the sawyer_tm VCorpus is a line of text. Use DocumentTermMaterix() to convert the vCorpus into tm’s bag-of-words format, DTM. # (sawyer_tm_dtm &lt;- DocumentTermMatrix(sawyer_tm)) This is a very sparse (nearly 100% sparse) matrix documents as rows and distinct words as columns. # group_by(chapter) %&gt;% # mutate(text = paste(text, collapse = &quot; &quot;)) %&gt;% # slice_head(n = 1) %&gt;% # select(chapter, text) # # sawyer_sent &lt;- sawyer %&gt;% # sentSplit(&quot;text&quot;) # # skimr::skim(sawyer) quanteda dafdafd tidytext dafdafd "],["sentimentanalysis.html", "Chapter 3 Sentiment Analysis", " Chapter 3 Sentiment Analysis Sentiment analysis is the extraction of the emotional intent of text. You can classify the polarity (positive | negative) or sentiment (angry | sad | happy | …) at the document, sentence, or feature level. To practice with real-world data, I will use the Customer reviews of London-based hotels data set hosted on data.world. hotel_raw contains reviews of the top 10 most- and least-expensive hotels in London. hotel_raw_1 &lt;- read_csv(&quot;https://query.data.world/s/2zsbemxf66vevuuc47jqe24n4zwl54&quot;) %&gt;% mutate(`Date Of Review` = lubridate::mdy(`Date Of Review`), `Property Name` = trimws(str_remove(`Property Name`, &quot;Hotel&quot;)), `Property Name` = trimws(str_remove(`Property Name`, &quot;The&quot;)), `Property Name` = case_when( str_detect(`Property Name`, &quot;^45 Park Lane&quot;) ~ &quot;45 Park Lane&quot;, str_detect(`Property Name`, &quot;^Apex&quot;) ~ &quot;Apex&quot;, str_detect(`Property Name`, &quot;^Bulgari&quot;) ~ &quot;Bulgari&quot;, str_detect(`Property Name`, &quot;^Corinthia&quot;) ~ &quot;Corinthia&quot;, str_detect(`Property Name`, &quot;^London Guest House&quot;) ~ &quot;Guest House&quot;, str_detect(`Property Name`, &quot;^Xenia&quot;) ~ &quot;Xenia&quot;, str_detect(`Property Name`, &quot;^Mandarin&quot;) ~ &quot;Mandarin&quot;, str_detect(`Property Name`, &quot;^Mondrian&quot;) ~ &quot;Mondrian&quot;, str_detect(`Property Name`, &quot;^Wellesley&quot;) ~ &quot;Wellesley&quot;, TRUE ~ `Property Name`), `Property Name` = factor(`Property Name`), review_id = row_number() ) %&gt;% janitor::clean_names(case = &quot;snake&quot;) %&gt;% select(review_id, everything()) skimr::skim(hotel_raw_1) ## Warning: There was 1 warning in `dplyr::summarize()`. ## ℹ In argument: `dplyr::across(tidyselect::any_of(variable_names), ## mangled_skimmers$funs)`. ## ℹ In group 0: . ## Caused by warning: ## ! There were 7010 warnings in `dplyr::summarize()`. ## The first warning was: ## ℹ In argument: `dplyr::across(tidyselect::any_of(variable_names), ## mangled_skimmers$funs)`. ## Caused by warning in `grepl()`: ## ! unable to translate &#39;Ottima qualit&lt;e0&gt; prezzo&#39; to a wide string ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 7009 remaining warnings. Table 3.1: Data summary Name hotel_raw_1 Number of rows 27330 Number of columns 7 _______________________ Column type frequency: character 3 Date 1 factor 1 numeric 2 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace review_title 0 1.00 1 508 0 22323 0 review_text 0 1.00 16 32759 0 27329 0 location_of_the_reviewer 3953 0.86 1 178 0 6624 0 Variable type: Date skim_variable n_missing complete_rate min max median n_unique date_of_review 1 1 2002-04-01 2018-10-18 2015-07-22 3870 Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts property_name 0 1 FALSE 20 Sav: 5417, Mon: 4330, Rem: 3028, Cor: 2820 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist review_id 0 1 13665.50 7889.64 1 6833.25 13665.5 20497.75 27330 ▇▇▇▇▇ review_rating 0 1 4.49 0.89 1 4.00 5.0 5.00 5 ▁▁▁▂▇ There are 27,330 reviews of 20 hotels posted between 2002-04-01 and 2018-10-18. This raw text needs cleaned. One issue is tags like &lt;e9&gt; and unicode characters like &lt;U+0440&gt;. One way to get rid of unicode characters is to convert them to ascii tags with iconv() and then remove the tags with str_remove(). For example, iconv() will change &lt;U+0093&gt; to ascii string “&lt;93&gt;” that you can remove with regex \"\\\\&lt;[:alnum]+\\\\&gt;]\" (more help with regex on RStudio’s cheat sheets). hotel_raw_2 &lt;- hotel_raw_1 %&gt;% mutate( review_text = iconv(review_text, from = &quot;&quot;, to = &quot;ASCII&quot;, sub = &quot;byte&quot;), review_text = str_remove_all(review_text, &quot;\\\\&lt;[[:alnum:]]+\\\\&gt;&quot;) ) I also want to remove reviews written in a foreign language. One blunt force way to handle this is to look for words common in other languages that do not also occur in English. hotel &lt;- hotel_raw_2 %&gt;% filter(!str_detect(review_text, &quot;( das )|( der )|( und )|( en )&quot;)) %&gt;% # German filter(!str_detect(review_text, &quot;( et )|( de )|( le )|( les )&quot;)) %&gt;% # French filter(!str_detect(review_text, &quot;( di )|( e )|( la )&quot;)) %&gt;% # Italian filter(!str_detect(review_text, &quot;( un )|( y )&quot;)) %&gt;% # Spanish select(review_id, everything()) That got rid of 3,557 rows. My cleansed data set hotel has 23,773 rows. "],["subjectivity-lexicons.html", "3.1 Subjectivity Lexicons", " 3.1 Subjectivity Lexicons There are three common sentiment lexicons. You commonly use Bing for polarity scoring, and AFINN for identifying emotions. Bing classifies words as positive or negative. sentiment_bing &lt;- get_sentiments(&quot;bing&quot;) sentiment_bing %&gt;% count(sentiment) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;Bing Lexicon&quot;) .cl-203dac02{}.cl-20375316{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-20375320{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2039cb00{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2039cb0a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2039d8ac{width:0.941in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8b6{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8b7{width:0.941in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8c0{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8c1{width:0.941in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8c2{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8ca{width:0.941in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-2039d8cb{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.2: Bing Lexicon sentimentnnegative4,781positive2,005Total6,786 The AFINN lexicon associates words with a manually rated valence integer between -5 (negative) and +5 (positive) by Finn Arup Nielsen. sentiment_afinn &lt;- get_sentiments(&quot;afinn&quot;) sentiment_afinn %&gt;% count(value) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;AFINN Lexicon&quot;) .cl-205efa9c{}.cl-2058d8a6{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2058d8b0{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-205b3d26{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-205b3d3a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-205b4f50{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f5a{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f64{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f65{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f6e{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f6f{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f70{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f78{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f79{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f82{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f8c{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f8d{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f8e{width:0.64in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-205b4f96{width:0.633in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.3: AFINN Lexicon valuen-516-443-3264-2966-13090112082448317244555Total2,477 The NRC lexicon associates words with eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) corresponding to the second level of Plutchik’s Wheel of Emotions and two sentiments (negative and positive). NRC was created by manual annotation on a crowdsourcing platform. Read more here. sentiment_nrc &lt;- get_sentiments(&quot;nrc&quot;) sentiment_nrc %&gt;% count(sentiment) %&gt;% adorn_totals() %&gt;% flextable() %&gt;% autofit() %&gt;% colformat_int(j = 2) %&gt;% set_caption(&quot;NRC Lexicon&quot;) .cl-2077144c{}.cl-206fe7a8{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-206fe7a9{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-2072face{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-2072fad8{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-20730c8a{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730c8b{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730c94{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730c95{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730c96{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730c9e{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730ca8{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730ca9{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730caa{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730cb2{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730cbc{width:0.988in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-20730cc6{width:0.71in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 3.4: NRC Lexicon sentimentnanger1,245anticipation837disgust1,056fear1,474joy687negative3,316positive2,308sadness1,187surprise532trust1,230Total13,872 "],["polarity-scoring.html", "3.2 Polarity Scoring", " 3.2 Polarity Scoring You can use three packages to measure text polarity. The simplest method is using tidytext. You transform your text into one-row per word with unnest_tokens(), join to one of the sentiment lexicons, and add up the positives and negatives. The polarity score is the net of positive - negative. qdap is more sophisticated. It takes into account valence shifters, surrounding words that change the intensity of a sentiment (e.g., “very”) or switch its direction (e.g., “not”). 3.2.1 tidytext The tidy way to score polarity is tagging individual words as “positive” and “negative” using the bing lexicon, then defining polarity as difference in counts. In principle, you ought to be able to use the positive|negative subset of NRC, or create weighted counts using AFINN. The qdap and sentimentr packages also correct for text length. A wordy review using twice as many positives as negatives shouldn’t score twice as positive. Those packages divide by \\(\\sqrt{n}\\) to reduce the impact of word count (longer reviews are still more emotional, just less so). Another “improvement” I employ below is capturing the words that registered as positive an negative. This is useful for explaining how the polarity score was calculated. I also attached the results back to the original data frame with an outer join since not all reviews would necessarily have any sentiment words (but they did). This leaves me with the original data, plus all my polarity metadata. hotel_tidy &lt;- hotel %&gt;% select(review_id, review_text) %&gt;% unnest_tokens(output = &quot;word&quot;, input = review_text) hotel_wordcount &lt;- hotel_tidy %&gt;% count(review_id) hotel_tidy_polarity_1 &lt;- hotel_tidy %&gt;% inner_join(get_sentiments(&quot;bing&quot;), by = &quot;word&quot;) %&gt;% group_by(review_id, sentiment) %&gt;% summarize(.groups = &quot;drop&quot;, n = n(), words = list(word)) %&gt;% pivot_wider(names_from = sentiment, values_from = c(n, words), values_fill = list(n = 0)) ## Warning in inner_join(., get_sentiments(&quot;bing&quot;), by = &quot;word&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 748865 of `x` matches multiple rows in `y`. ## ℹ Row 5608 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to ## silence this warning. hotel_tidy_polarity_bing &lt;- hotel %&gt;% left_join(hotel_wordcount, by = &quot;review_id&quot;) %&gt;% left_join(hotel_tidy_polarity_1, by = &quot;review_id&quot;) %&gt;% mutate(polarity_score = (n_positive - n_negative) / sqrt(n), polarity_desc = if_else(polarity_score &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) Out of curiosity, I’ll try this with AFINN too. hotel_tidy_polarity_2 &lt;- hotel_tidy %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(review_id) %&gt;% summarize(.groups = &quot;drop&quot;, sentiment = sum(value), words = list(word)) hotel_tidy_polarity_afinn &lt;- hotel %&gt;% left_join(hotel_wordcount, by = &quot;review_id&quot;) %&gt;% left_join(hotel_tidy_polarity_2, by = &quot;review_id&quot;) %&gt;% mutate(polarity_score = sentiment / sqrt(n), polarity_desc = if_else(polarity_score &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) How should we present these results? One way is to treat polarity as the numeric measure and group by the factor variable property_name. Here are my Bing results. hotel_tidy_polarity_bing %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(polarity_score, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Bing Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) And here is is with AFINN. hotel_tidy_polarity_afinn %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(polarity_score, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;AFINN Polarity = sentiment / sqrt(n_words)&quot;) Not too different. 2 of the top 3 are the same. The bottom 4 are the same group, just shuffled. Savoy fared better in AFINN than in Bing. The data set includes a numeric rating review_rating (1-5). Does the polarity score reveal anything that the numeric rating doesn’t already tell you? hotel_tidy_polarity_bing %&gt;% filter(!is.na(polarity_score)) %&gt;% ggplot(aes(x = as_factor(review_rating), y = polarity_score)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) Most reviews are positive - even for 2-rated hotels. While sentiment does increase with review rating, there are plenty of reviews with a rating of 5 and a polarity score &lt;0. Let’s dig into that a little. Here is a 1-rated review with a decent polarity score. hotel_tidy_polarity_bing %&gt;% filter(review_rating == 1) %&gt;% slice_max(polarity_score) %&gt;% select(polarity_score, review_text) %&gt;% flextable() %&gt;% autofit() .cl-24ef7a64{}.cl-24e86328{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-24e86332{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-24eb23ba{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-24eb23c4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-24eb3544{width:1.235in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24eb354e{width:32.807in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24eb3558{width:1.235in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24eb3559{width:32.807in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}polarity_scorereview_text0.8728716Stayed here many times both for business and pleasure, alone, with my wife and even with extended family and children. It is in fact impossible to seperate the business and pleasure stays because everytime was a breathtakingly delectable pleasure. Meeting friends and colleagues whether in the lobby one of the resturants always left an impressive memorable impression. Alas, I haven't been able to visit again for sometime - either fully booked or are not able to guarantee convenient parking for my personal chauffeur and car. Well, that is amusing - I the reviewer treating the rating as a kind of ranking (first place!). How about a 5-rating with negative sentiment? hotel_tidy_polarity_bing %&gt;% filter(review_rating == 5) %&gt;% slice_min(polarity_score) %&gt;% select(polarity_score, review_text) %&gt;% flextable() %&gt;% autofit() .cl-25040542{}.cl-24fd3302{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-24fd330c{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-24ffa47a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-24ffa484{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-24ffb672{width:1.235in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24ffb67c{width:22.26in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24ffb686{width:1.235in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-24ffb690{width:22.26in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}polarity_scorereview_text-0.70014Some design faults in the bathroom - no stool, misplaced grab handles and vanity mirror. | Very disappointing experience in Savoy Grill. Good quality ingredients but poorly presented and tasteless. Numerous mistakes in service including charging for expensive drinks which we did not have. Service charge revoked and booking for following night cancelled. | Again, I think they got it backwards. The polarity scoring can reveal why some hotels rated worse by looking at the words used. (this plot di not come out well). hotel_tidy_polarity_bing %&gt;% mutate(review_rating = as.factor(review_rating)) %&gt;% filter(!is.na(polarity_desc)) %&gt;% select(!c(words_positive, words_negative)) %&gt;% # no lists allowed unnest_tokens(&quot;word&quot;, review_text) %&gt;% anti_join(stop_words, by = &quot;word&quot;) %&gt;% filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% filter(!word %in% c(&quot;hotel&quot;, &quot;stay&quot;, &quot;night&quot;, &quot;london&quot;)) %&gt;% count(review_rating, polarity_desc, word) %&gt;% group_by(review_rating, polarity_desc) %&gt;% slice_max(order_by = n, n = 8, with_ties = FALSE) %&gt;% mutate(n = if_else(polarity_desc == &quot;Negative&quot;, -n, n), word = paste0(if_else(polarity_desc == &quot;Negative&quot;, &quot;-&quot;, &quot;+&quot;), word)) %&gt;% ungroup() %&gt;% arrange(review_rating, n) %&gt;% ggplot(aes(x = fct_inorder(word), y = n, fill = polarity_desc, color = polarity_desc)) + geom_col(alpha = 0.6) + facet_wrap(~as.factor(review_rating), scales = &quot;free&quot;) + scale_fill_few() + scale_color_few() + coord_flip() + theme_minimal() + theme(legend.position = &quot;top&quot;) + labs(title = &quot;Top Words by review type&quot;, y = &quot;Word Count&quot;, x = NULL, fill = NULL, color = NULL) Word clouds are a nice way to get an overview of the data. hotel_tidy_polarity_bing %&gt;% unnest_tokens(output = &quot;word&quot;, input = review_text) %&gt;% anti_join(stop_words, by = &quot;word&quot;) %&gt;% filter(!str_detect(word, &quot;[0-9]&quot;) &amp; !is.na(polarity_desc)) %&gt;% filter(!word %in% c(&quot;hotel&quot;, &quot;stay&quot;, &quot;night&quot;, &quot;london&quot;)) %&gt;% count(word, polarity_desc, wt = n) %&gt;% pivot_wider(names_from = polarity_desc, values_from = n, values_fill = 0) %&gt;% data.table::data.table() %&gt;% as.matrix(rownames = &quot;word&quot;) %&gt;% wordcloud::comparison.cloud(max.words = 20, title.size = 1.5) ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## wonderful could not be fit on page. It will not be plotted. ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## service could not be fit on page. It will not be plotted. ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## restaurant could not be fit on page. It will not be plotted. ## Warning in wordcloud::comparison.cloud(., max.words = 20, title.size = 1.5): ## special could not be fit on page. It will not be plotted. 3.2.2 sentimentr sentimentr calculates polarity at the sentence level. It improves on tidytext in that it takes into account the context in which the sentiment words occur, that is, the valence shifters. A negator flips the sign of a polarized word (e.g., “I do not like it.”). See lexicon::hash_valence_shifters[y==1]. An amplifier (intensifier) increases the impact (e.g., “I really like it.”). See lexicon::hash_valence_shifters[y==2]. A de-amplifier (downtoner) reduces the impact (e.g., “I hardly like it.”). See lexicon::hash_valence_shifters[y==3]. An adversative conjunction overrules the previous clause containing a polarized word (e.g., “I like it but it’s not worth it.”). See lexicon::hash_valence_shifters[y==4]. sentimentr uses a lexicon package combined from the syuzhet and lexicon packages. Positive words are scored +1 and negative words are scored -1. sentimentr identifies clusters of words within sentences of the text. The 4 words before and 2 words after are candidate valence shifters. Polarized words are weighted by the valence shifter weights: negators = -1; amplifiers and de-amplifiers = 1.8; adversative conjunctions decrease the value of the prior cluster and increase the value of the following cluster. Neutral words hold no value, but do affect the word count. hotel_sentr_polarity_1 &lt;- hotel %&gt;% mutate(sentences = get_sentences(review_text)) %$% sentiment_by(sentences, review_id) hotel_sentr_polarity &lt;- hotel %&gt;% left_join(hotel_sentr_polarity_1, by = &quot;review_id&quot;) %&gt;% mutate(polarity_desc = if_else(ave_sentiment &gt;= 0, &quot;Positive&quot;, &quot;Negative&quot;)) Here is the chart treating polarity as the numeric measure and group by the factor variable property_name. hotel_sentr_polarity %&gt;% group_by(property_name) %&gt;% mutate(median_polarity = median(ave_sentiment, na.rm = TRUE)) %&gt;% ungroup() %&gt;% arrange(median_polarity) %&gt;% ggplot(aes(x = fct_inorder(property_name), y = ave_sentiment)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + geom_hline(yintercept = 0, linetype = &quot;longdash&quot;, color = &quot;#60BD68&quot;, size = 1.25) + coord_flip() + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Sentimentr Polarity&quot;) Here, Xenia came out on top. The data set includes a numeric rating review_rating (1-5). Does the polarity score reveal anything that the numeric rating doesn’t already tell you? hotel_sentr_polarity %&gt;% filter(!is.na(ave_sentiment)) %&gt;% ggplot(aes(x = as_factor(review_rating), y = ave_sentiment)) + geom_jitter(width = 0.2, alpha = 0.3, color = &quot;#5DA5DA&quot;, size = 1) + geom_boxplot(alpha = 0) + theme_minimal() + labs(title = &quot;Few Reviews for a Reason?&quot;, subtitle = &quot;Hotels with few reviews tend to have negative reviews.&quot;, x = NULL, y = &quot;Sentiment Polarity Score&quot;, caption = &quot;Polarity = (n_pos - n_neg) / sqrt(n_words)&quot;) One nice feature of sentimentr is that it creates a highlighted text based on sentiment score (green = positive, red = negative). hotel_sentr_polarity %&gt;% highlight() 3.2.3 qdap qdap::polarity(text.var, grouping.var = NULL) calculates the polarity score for each character string text.var, grouping by optional character vector grouping.var. polarity uses the sentiment dictionary to tag polarized words. It considers a context cluster of words around polarized words as valence shifters (neutral, negator, amplifier, or de-amplifier). Neutral words hold no value but do affect word count. polarity applies the dictionary weights to each polarized word and then further weights by the number and position of the valence shifters. Last, it sums the context cluster and divides by the square root of the word count, yielding an unbounded polarity score. # hotel_sentr_polarity &lt;- hotel %&gt;% # mutate(sentences = get_sentences(review_text)) %&gt;% # sentiment_by(sentences, list(review_id)) # hotel_qdap_polarity &lt;- hotel %$% # polarity(review_text, review_id) # # scores(hotel_qdap_polarity) The counts() function returns one row for each line of text. It includes a list of the positive and negative words that contribute to the polarity score. Line 57 has a polarity score of zero because it has a pair of positive and negative words. # sawyer[57,] # counts(sawyer_tm_polarity)[57,] # counts(sawyer_tm_polarity)[57, c(&quot;pos.words&quot;, &quot;neg.words&quot;)] %&gt;% unlist() Oh, but wait - Twain doesn’t use mighty as a positive adjective, but rather, as an amplifier adverb. Mighty appears sawyer %&gt;% filter(str_detect(text, \"mighty\")) %&gt;% nrow times in Tom Sawyer. We should remove it from the polarity.frame and add it to the amplifiers. # custom_frame &lt;- sentiment_frame( # positives = qdapDictionaries::positive.words[qdapDictionaries::positive.words != &quot;mighty&quot;], # negatives = qdapDictionaries::negative.words # ) # # sawyer_tm_polarity_2 &lt;- sawyer %&gt;% # mutate(text = str_remove_all(text, &quot;\\\\_&quot;)) %$% # polarity( # text, chapter, # polarity.frame = custom_frame, # amplifiers = sort(c(qdapDictionaries::amplification.words, &quot;mighty&quot;)) # ) # # counts(sawyer_tm_polarity_2)[57,] Something is still wrong here. It removed mighty as a positive word, but did not apply it as amplifier. It seems to be confused by the presence of the comma in “tomorrow, to punish”. I’ll drop the matter for now, but perhaps how we parse the data into rows makes a difference. It also advises that you run SentSplit() on the data first, but the function never stopped running, so I abandoned it. Here is a plot of the polarity results. # plot(sawyer_tm_polarity_2) Chapter 22 had the lowest polarity score and chapter 34 the highest. # sawyer_tm_polarity_2 %&gt;% # scores() %&gt;% # mutate(chapter = as.integer(chapter)) %&gt;% # ggplot(aes(x = chapter, y = ave.polarity)) + # geom_point() + # geom_segment(aes(x = chapter, xend = chapter, y = 0, yend = ave.polarity)) + # geom_smooth() + # geom_hline(yintercept = 0, color = &quot;red&quot;) + # theme_minimal() + # labs(title = &quot;Adventures of Tom Sawyer Chronological Polarity&quot;) Create to strings, one with the positive chapters, and one from the negative chapters. # sawyer_poloarity_pos &lt;- sawyer_tm_polarity_2$all %&gt;% # filter(polarity &gt; 0) %&gt;% # pull(text.var) %&gt;% # paste(collapse = &quot; &quot;) # # sawyer_poloarity_neg &lt;- sawyer_tm_polarity_2$all %&gt;% # filter(polarity &lt; 0) %&gt;% # pull(text.var) %&gt;% # paste(collapse = &quot; &quot;) # # sawyer_polarity_tdm &lt;- c(sawyer_poloarity_pos, sawyer_poloarity_neg) %&gt;% # VectorSource() %&gt;% # VCorpus() %&gt;% # TermDocumentMatrix(control = list(weighting = weightTfIdf, # removePunctuation = TRUE, # stopwords = stopwords(kind = &quot;en&quot;))) Often authors will use more words when they are more passionate. Lengthy reviews may inflate overall sentiment since the reviews will inherently contain more positive or negative language as the review lengthens. "],["emotion-classification.html", "3.3 Emotion Classification", " 3.3 Emotion Classification Bar plots are usually a clearer alternative, but radar charts do look pretty. https://en.wikipedia.org/wiki/Robert_Plutchik#/media/File:Plutchik-wheel.svg # dat &lt;- sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;nrc&quot;), by = &quot;word&quot;) %&gt;% # filter(!sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% # mutate(sentiment = case_when(sentiment == &quot;joy&quot; ~ 1, # sentiment == &quot;trust&quot; ~ 2, # sentiment == &quot;fear&quot; ~ 3, # sentiment == &quot;surprise&quot; ~ 4, # sentiment == &quot;sadness&quot; ~ 5, # sentiment == &quot;disgust&quot; ~ 6, # sentiment == &quot;anger&quot; ~ 7, # sentiment == &quot;anticipation&quot; ~ 8, # TRUE ~ 9), # sentiment = factor(sentiment, levels = c(1:9), # labels = c(&quot;joy&quot;, &quot;trust&quot;, &quot;fear&quot;, &quot;surprise&quot;, # &quot;sadness&quot;, &quot;disgust&quot;, &quot;anger&quot;, # &quot;anticipation&quot;, &quot;other&quot;))) %&gt;% # count(sentiment) # # dat %&gt;% # radarchart::chartJSRadar() # library(gutenbergr) # sawyer_raw &lt;- gutenberg_works(title == &quot;The Adventures of Tom Sawyer&quot;) %&gt;% # gutenberg_download() # hotel %&gt;% filter(is.na(date_of_review)) # min(hotel$date_of_review, na.rm = TRUE) # skimr::skim(sawyer_raw) sawyer_raw is a tibble with 8,832 rows, with one row per line of text and 0-78 characters per line. This is a corpus with a single document and no metadata (although you could get multiple books at once, and attach the title and author as metadata). Most text requires some cleaning. I will want to remove the title lines, and add add some metadata, including the chapter number and line number. # sawyer &lt;- sawyer_raw %&gt;% # tail(-455) %&gt;% # chapter 1 starts on line 456 # mutate( # is_chap = str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE)), # chapter = cumsum(is_chap) # ) %&gt;% # filter(text != &quot;&quot; &amp; !str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE))) %&gt;% # mutate(line = row_number()) %&gt;% # select(line, chapter, text) # head(sawyer) A subjectivity lexicon is a predefined list of words associated with emotional context such as positive/negative. qdap::polarity() uses the lexicon::hash_sentiment_huliu lexicon with sentiment values in (+1, 0, -1.05, -1, -2). It is similar to tidytext::sentiments() AFINN lexicon (-5 to 5). tidytext::sentiments() also includes the NRC lexicon (classifying among 8 emotions) and the Bing lexicon (classifying as positive or negative). Subjectivity lexicons are typically short (a few thousand words), but work because of Zipf’s law. According to this law, the nth-ranked item in a frequency table has a frequency count equal to 1/n of the top-ranked item. So infrequently used words are used very infrequently. "],["comparison-cloud.html", "3.4 Comparison Cloud", " 3.4 Comparison Cloud # sawyer_tidy %&gt;% # anti_join(stop_words, by = &quot;word&quot;) %&gt;% # filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% # inner_join(get_sentiments(&quot;nrc&quot;), by = &quot;word&quot;) %&gt;% # filter(sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&gt;% # count(chapter, sentiment) %&gt;% # group_by(chapter) %&gt;% # mutate(pct = n / sum(n)) %&gt;% # ggplot(aes(x = chapter, y = pct, fill = sentiment, color = sentiment)) + # geom_area(alpha = 0.6) + # scale_x_continuous(breaks = 1:35, minor_breaks = NULL) + # scale_fill_few() + # scale_color_few() + # geom_hline(yintercept = 0.5, linetype = 2) + # theme_minimal() + # theme(legend.position = &quot;top&quot;) + # labs(title = &quot;Sentiment Proportion by Chapter&quot;, x = NULL, y = NULL, fill = NULL, color = NULL) # sawyer_tidy %&gt;% # anti_join(stop_words, by = &quot;word&quot;) %&gt;% # filter(!str_detect(word, &quot;[0-9]&quot;)) %&gt;% # inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% # ggplot(aes(x = value)) + # geom_density(fill = ggthemes::few_pal()(1), alpha = 0.6) + # theme_minimal() + # labs(title = &quot;AFINN Score Density&quot;) # sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;bing&quot;), by = &quot;word&quot;) %&gt;% # count(chapter, line, sentiment) %&gt;% # pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% # mutate(polarity = positive - negative) %&gt;% # ggplot(aes(x = as.factor(chapter), y = polarity)) + # geom_boxplot() + # geom_jitter(aes(color = as.factor(chapter)), alpha = 0.6, size = .5, show.legend = FALSE) + # theme_minimal() + # labs(title = &quot;Chapter Polarity&quot;) # sawyer_tidy %&gt;% # inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% # count(chapter, value) %&gt;% # ggplot(aes(area = n, fill = value)) + # treemapify::geom_treemap() One more cleaning step. Since these reviews are recorded in web sites, they are likely rife with spelling errors. I’ll use the misspellings dataset from the fuzzyjoin package to remove them. # data(&quot;misspellings&quot;, package = &quot;fuzzyjoin&quot;) # # # Some misspelling have multiple correct possibilities - choose one # misspellings_winner &lt;- misspellings %&gt;% # group_by(misspelling) %&gt;% # slice(n = 1) # # hotel &lt;- hotel_raw_3 %&gt;% # unnest_tokens(&quot;word&quot;, review_text) %&gt;% # left_join(misspellings, by = c(&quot;word&quot; = &quot;misspelling&quot;)) %&gt;% # word = coalesce(correct, word) # hotel_raw_2 %&gt;% filter(review_id %in% c(28)) %&gt;% # select(review_text) %&gt;% # flextable::flextable() "],["statistical-test.html", "3.5 Statistical Test", " 3.5 Statistical Test Since this is a comparison of a numeric outcome to a multinominal predictor (property_name) or ordinal predictor(review_rating), you could perform an ANOVA test. my_aov &lt;- aov(polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) my_anova &lt;- anova(my_aov) broom::tidy(my_anova) ## # A tibble: 2 × 6 ## term df sumsq meansq statistic p.value ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 as.factor(review_rating) 4 908. 227. 1875. 0 ## 2 Residuals 23271 2818. 0.121 NA NA #plot(TukeyHSD(my_aov)) my_lm &lt;- lm(polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) summary(my_lm) ## ## Call: ## lm(formula = polarity_score ~ as.factor(review_rating), data = hotel_tidy_polarity_bing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.50252 -0.23263 -0.00321 0.22338 2.88057 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.14021 0.01574 -8.91 &lt;2e-16 *** ## as.factor(review_rating)2 0.22704 0.02143 10.59 &lt;2e-16 *** ## as.factor(review_rating)3 0.47721 0.01838 25.97 &lt;2e-16 *** ## as.factor(review_rating)4 0.80924 0.01653 48.96 &lt;2e-16 *** ## as.factor(review_rating)5 0.94258 0.01597 59.01 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.348 on 23271 degrees of freedom ## (497 observations deleted due to missingness) ## Multiple R-squared: 0.2438, Adjusted R-squared: 0.2436 ## F-statistic: 1875 on 4 and 23271 DF, p-value: &lt; 2.2e-16 tbl_regression(my_lm) #qkuhpyrjwq table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #qkuhpyrjwq thead, #qkuhpyrjwq tbody, #qkuhpyrjwq tfoot, #qkuhpyrjwq tr, #qkuhpyrjwq td, #qkuhpyrjwq th { border-style: none; } #qkuhpyrjwq p { margin: 0; padding: 0; } #qkuhpyrjwq .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qkuhpyrjwq .gt_caption { padding-top: 4px; padding-bottom: 4px; } #qkuhpyrjwq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qkuhpyrjwq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qkuhpyrjwq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qkuhpyrjwq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qkuhpyrjwq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qkuhpyrjwq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qkuhpyrjwq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qkuhpyrjwq .gt_column_spanner_outer:first-child { padding-left: 0; } #qkuhpyrjwq .gt_column_spanner_outer:last-child { padding-right: 0; } #qkuhpyrjwq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qkuhpyrjwq .gt_spanner_row { border-bottom-style: hidden; } #qkuhpyrjwq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #qkuhpyrjwq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qkuhpyrjwq .gt_from_md > :first-child { margin-top: 0; } #qkuhpyrjwq .gt_from_md > :last-child { margin-bottom: 0; } #qkuhpyrjwq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qkuhpyrjwq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qkuhpyrjwq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qkuhpyrjwq .gt_row_group_first td { border-top-width: 2px; } #qkuhpyrjwq .gt_row_group_first th { border-top-width: 2px; } #qkuhpyrjwq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qkuhpyrjwq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qkuhpyrjwq .gt_first_summary_row.thick { border-top-width: 2px; } #qkuhpyrjwq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qkuhpyrjwq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qkuhpyrjwq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qkuhpyrjwq .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #qkuhpyrjwq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qkuhpyrjwq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qkuhpyrjwq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qkuhpyrjwq .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qkuhpyrjwq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qkuhpyrjwq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qkuhpyrjwq .gt_left { text-align: left; } #qkuhpyrjwq .gt_center { text-align: center; } #qkuhpyrjwq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qkuhpyrjwq .gt_font_normal { font-weight: normal; } #qkuhpyrjwq .gt_font_bold { font-weight: bold; } #qkuhpyrjwq .gt_font_italic { font-style: italic; } #qkuhpyrjwq .gt_super { font-size: 65%; } #qkuhpyrjwq .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #qkuhpyrjwq .gt_asterisk { font-size: 100%; vertical-align: 0; } #qkuhpyrjwq .gt_indent_1 { text-indent: 5px; } #qkuhpyrjwq .gt_indent_2 { text-indent: 10px; } #qkuhpyrjwq .gt_indent_3 { text-indent: 15px; } #qkuhpyrjwq .gt_indent_4 { text-indent: 20px; } #qkuhpyrjwq .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value as.factor(review_rating)     1 — —     2 0.23 0.19, 0.27     3 0.48 0.44, 0.51     4 0.81 0.78, 0.84     5 0.94 0.91, 0.97 1 CI = Confidence Interval "],["final-words.html", "Chapter 4 Final Words", " Chapter 4 Final Words We have finished a nice book. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
