[["data-prep.html", "Chapter 1 Data Preparation", " Chapter 1 Data Preparation This section covers how to prepare a corpus for text analysis. I’ll work with the customer reviews of London-based hotels data set hosted on data.world. hotel_raw contains 27K reviews of the ten most- and ten least-expensive hotels in London. The csv file is located online here. I saved it to my \\inputs directory. To help my analysis steps go quicker, I’ll just use 10% of the reviews. library(tidyverse) library(tidytext) library(janitor) library(scales) library(glue) set.seed(12345) hotel_0 &lt;- read_csv( &quot;input/london_hotel_reviews.csv&quot;, col_types = &quot;cicccc&quot;, col_names = c(&quot;hotel&quot;, &quot;rating&quot;, &quot;title&quot;, &quot;review&quot;, &quot;reviewer_loc&quot;, &quot;review_dt&quot;), skip = 1 ) %&gt;% mutate(review_id = row_number()) %&gt;% select(review_id, everything(), -c(title, review_dt)) %&gt;% slice_sample(n = 1700) glimpse(hotel_0) ## Rows: 1,700 ## Columns: 5 ## $ review_id &lt;int&gt; 14478, 24627, 17104, 25306, 10904, 21306, 605, 14923, 226… ## $ hotel &lt;chr&gt; &quot;The Savoy&quot;, &quot;Ridgemount Hotel&quot;, &quot;Apex London Wall Hotel&quot;… ## $ rating &lt;int&gt; 5, 5, 4, 5, 5, 5, 1, 1, 2, 5, 4, 4, 2, 5, 5, 5, 5, 5, 5, … ## $ review &lt;chr&gt; &quot;Love Love Love The Savoy. If you are looking for a luxe … ## $ reviewer_loc &lt;chr&gt; &quot;Southend-on-Sea, United Kingdom&quot;, &quot;Canberra, Australia&quot;,… "],["scrub.html", "1.1 Scrub", " 1.1 Scrub The data needs to be cleaned. I’ll follow some of the techniques used by Nagelkerke (2020). One issue is tags like &lt;e9&gt; and unicode characters like &lt;U+0440&gt;. One way to get rid of unicode characters is to convert them to ASCII tags with iconv() and then remove the ASCII tags with str_remove(). E.g., iconv() converts &lt;U+0093&gt; to &lt;93&gt; which you can remove with regex \"\\\\&lt;[:alnum]+\\\\&gt;]\".1 There are also some reviews in other languages that I’ll just drop. And some hotel names are pretty long, so I’ll abbreviate them. hotel_1 &lt;- hotel_0 %&gt;% mutate( # Create ASCII bytes review = iconv(review, from = &quot;&quot;, to = &quot;ASCII&quot;, sub = &quot;byte&quot;), # Remove &lt;..&gt; review = str_remove_all(review, &quot;\\\\&lt;[[:alnum:]]+\\\\&gt;&quot;), # Remove &lt;U+....&gt; review = str_remove_all(review, &quot;\\\\&lt;U\\\\+[[:alnum:]]{4}\\\\&gt;&quot;), # Only keep letters, numbers, and apostrophes. review = str_remove_all(review, &quot;[^[:alnum:][\\\\s][\\\\&#39;]]&quot;), review = str_squish(review), # Shorten some of the hotel names. hotel = str_remove_all( hotel, &quot;( - .*)|(, .*)|( Hotel)|( London)|(The )|( at .*)|( Hyde .*)|( Knights.*)&quot; ), hotel = factor(hotel, ordered = TRUE), # Reducing number of hotels for modeling simplicity. hotel = fct_lump_prop(hotel, prop = .05), # Bin common locations, reviewer_loc = factor(case_when( str_detect(reviewer_loc, &quot;(London)|(United Kingdom)|(UK)&quot;) ~ &quot;United Kingdom&quot;, str_detect(reviewer_loc, &quot;(New York)|(California)&quot;) ~ &quot;United States&quot;, TRUE ~ &quot;Other&quot; )), # Low ratings are so rare, lump the bottom two. rating = fct_collapse(as.character(rating), `1-2` = c(&quot;1&quot;, &quot;2&quot;)), # Interesting metadata raw_chrcnt = str_length(review) ) %&gt;% # Exclude reviews written in a foreign language. One heuristic to handle this # is to look for words common in other languages that do not also occur in English. filter( !str_detect(review, &quot;( das )|( der )|( und )|( en )&quot;), # German !str_detect(review, &quot;( et )|( de )|( le )|( les )&quot;), # French !str_detect(review, &quot;( di )|( e )|( la )&quot;), # Italian !str_detect(review, &quot;( un )|( y )&quot;), # Spanish raw_chrcnt &gt; 0 ) That might be enough. Let’s explore the data. We have 9 hotels. Reviewers are binned into 3 locations. 90% of reviews rate the property a 4 or 5. Some reviews are as small as 1 character, but they can get quite large. skimr::skim(hotel_1) Table 1.1: Data summary Name hotel_1 Number of rows 1448 Number of columns 6 _______________________ Column type frequency: character 1 factor 3 numeric 2 ________________________ Group variables None Variable type: character skim_variable n_missing complete_rate min max empty n_unique whitespace review 0 1 1 7157 0 1448 0 Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts hotel 0 1 TRUE 10 Sav: 307, Mon: 237, Rem: 176, Cor: 156 rating 0 1 FALSE 4 5: 959, 4: 299, 3: 115, 1-2: 75 reviewer_loc 0 1 FALSE 3 Oth: 830, Uni: 549, Uni: 69 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist review_id 0 1 13972.61 7879.17 34 7063.5 14472 20657 27295 ▇▇▇▇▇ raw_chrcnt 0 1 712.05 653.40 1 308.0 521 870 7157 ▇▁▁▁▁ Nagelkerke (2020) recommends removing punctuation to focus on the entire text rather than the sentences within. Nagelkerke also suggests removing very short (&lt;= 3 chars) for anything other than sentiment analysis. I’m going to keep punctuation and short reviews for now even though some of those extremely short reviews are gibberish. References "],["tokenize.html", "1.2 Tokenize", " 1.2 Tokenize Most models are based on tokenized text. Even if you are interested in working with bigrams, tokenize into words to clean and regularize the data first. token_0 &lt;- hotel_1 %&gt;% select(review_id, review) %&gt;% unnest_tokens(&quot;word&quot;, review) # Attach word counts back to main data frame, just to aid understanding. hotel_2 &lt;- hotel_1 %&gt;% inner_join(count(token_0, review_id, name = &quot;raw_wordcnt&quot;), by = join_by(review_id)) hotel_2 %&gt;% select(raw_chrcnt, raw_wordcnt) %&gt;% summary() ## raw_chrcnt raw_wordcnt ## Min. : 1 Min. : 1.0 ## 1st Qu.: 308 1st Qu.: 56.0 ## Median : 521 Median : 95.0 ## Mean : 712 Mean : 131.8 ## 3rd Qu.: 870 3rd Qu.: 163.0 ## Max. :7157 Max. :1331.0 "],["spell-check.html", "1.3 Spell-check", " 1.3 Spell-check Run a spell-check to regularize the data. It’s possible to land on the wrong correction, but there is probably more to gain than lose. Only a very small fraction of these tokens were misspellings. # There are multiple possible right spellings, so just choose one. spell_check &lt;- fuzzyjoin::misspellings %&gt;% distinct(misspelling, .keep_all = TRUE) token_1 &lt;- token_0 %&gt;% left_join(spell_check, by = join_by(word == misspelling)) %&gt;% mutate(word = coalesce(correct, word)) %&gt;% select(-correct) # Only .09% of words were misspelled. mean(token_0$word != token_1$word) ## [1] 0.000964401 # Examples. tibble(before = token_0$word, after = token_1$word) %&gt;% filter(before != after) %&gt;% count(before, after, sort = TRUE) ## # A tibble: 85 × 3 ## before after n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 didnt didn&#39;t 35 ## 2 wasnt wasn&#39;t 16 ## 3 definately definitely 8 ## 4 helpfull helpful 8 ## 5 accomodating accommodating 4 ## 6 definetly definitely 4 ## 7 upto up to 4 ## 8 accomodation accommodation 3 ## 9 accomodations accommodations 3 ## 10 altho although 3 ## # ℹ 75 more rows "],["lemmatize.html", "1.4 Lemmatize", " 1.4 Lemmatize Stemming and lemmatizing convert word variations like “staying”, “stayed”, and “stay” into a generic form: “stay”. Stemming tends to chop off endings to create a root word, but the stem is often not a word itself. E.g., “staying” becomes “stai”. Lemmatize gives you the more natural “stay”. token_2 &lt;- token_1 %&gt;% mutate(word = textstem::lemmatize_words(word)) tibble(before = token_1$word, after = token_2$word) %&gt;% filter(before != after) %&gt;% count(before, after, sort = TRUE) ## # A tibble: 2,711 × 3 ## before after n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 was be 4156 ## 2 is be 2291 ## 3 were be 1522 ## 4 had have 1224 ## 5 are be 916 ## 6 an a 586 ## 7 stayed stay 550 ## 8 rooms room 528 ## 9 well good 440 ## 10 more much 341 ## # ℹ 2,701 more rows "],["remove-stop-words.html", "1.5 Remove Stop Words", " 1.5 Remove Stop Words Stop words usually add no value, but you should pay attention to what you are dropping. Be ready to add pertinent words back and perhaps drop others. # Start with a standard list. stop &lt;- tidytext::stop_words %&gt;% # Remove potentially useful words from stop list. filter(!word %in% c(&quot;appreciate&quot;, &quot;room&quot;, &quot;first&quot;)) %&gt;% # Add custom stop words. bind_rows(tibble(word = c(&quot;hotel&quot;, &quot;stay&quot;))) token &lt;- anti_join(token_2, stop, by = &quot;word&quot;) # Most frequently removed words token_2 %&gt;% anti_join(token, by = join_by(review_id, word)) %&gt;% count(word, sort = TRUE) ## # A tibble: 459 × 2 ## word n ## &lt;chr&gt; &lt;int&gt; ## 1 the 12284 ## 2 be 10251 ## 3 and 7252 ## 4 a 6109 ## 5 to 4818 ## 6 in 3322 ## 7 we 3066 ## 8 of 2769 ## 9 i 2767 ## 10 have 2533 ## # ℹ 449 more rows "],["prepped-data.html", "1.6 Prepped Data", " 1.6 Prepped Data Now that the data is prepped, created a stylized review text. prepped_hotel &lt;- token %&gt;% summarize( .by = review_id, prepped_review = paste(word, collapse = &quot; &quot;), prepped_wrdcnt = n() ) %&gt;% inner_join(hotel_2, by = join_by(review_id)) %&gt;% relocate(prepped_review, prepped_wrdcnt, .after = last_col()) prepped_hotel %&gt;% select(review_id, review, prepped_review) %&gt;% head(n = 1) %&gt;% flextable::flextable() %&gt;% flextable::valign(valign = &quot;top&quot;) %&gt;% flextable::autofit() .cl-4d4d0a52{}.cl-4d45a870{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4d45a87a{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4d487e60{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4d487e6a{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4d487e74{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4d487e75{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4d489206{width:0.918in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d489207{width:23.812in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d489210{width:9.742in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d48921a{width:0.918in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d489224{width:23.812in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4d489225{width:9.742in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}review_idreviewprepped_review14,478Love Love Love The Savoy If you are looking for a luxe hotel that isn't stuffy this is the place for you You feel like a millionaire even if you're not one and it's a great place to hang out if you fancy keeping off the streets of London for a while Classy decor wonderful food and cocktails and the staff are wonderful it is an absolute allrounder and if I could afford it I would probably live therelove love love savoy luxe stuffy feel millionaire hang fancy street london classy decor wonderful food cocktail staff wonderful absolute allrounder afford live "],["bigrams.html", "1.7 Bigrams", " 1.7 Bigrams If you intend to present bigrams, don’t simply tokenize the raw or prepped text into bigrams because you don’t want stop words in bigram, nor do you want words that aren’t actually adjacent because you’ve removed stop words. Instead, tokenize into bigrams, split the bigrams into words, and filter out rows where one or both words is stop word. # Reassemble token_2 into text and re-tokenize so you get the spelling corrections. bigram_0 &lt;- token_2 %&gt;% summarize(.by = review_id, reconstructed = paste(word, collapse = &quot; &quot;)) %&gt;% unnest_tokens(&quot;bigram&quot;, reconstructed, token = &quot;ngrams&quot;, n = 2) # Remove bigrams where one or both words are stop words. bigram &lt;- bigram_0 %&gt;% separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% anti_join(stop, by = join_by(word1 == word)) %&gt;% anti_join(stop, by = join_by(word2 == word)) %&gt;% mutate(bigram = paste(word1, word2)) %&gt;% select(review_id, bigram) # Example bind_cols( hotel_2 %&gt;% filter(review_id == hotel_2[1, ]$review_id) %&gt;% select(review), bigram %&gt;% filter(review_id == hotel_2[1, ]$review_id) %&gt;% summarize(bigrams = paste(bigram, collapse = &quot;\\n&quot;)) ) %&gt;% flextable::flextable() %&gt;% flextable::autofit() %&gt;% flextable::width(j = 1, width = 4.5, unit = &quot;in&quot;) %&gt;% flextable::width(j = 2, width = 1.5, unit = &quot;in&quot;) %&gt;% flextable::valign(valign = &quot;top&quot;) .cl-4e950702{}.cl-4e8edb5c{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4e8edb66{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4e91213c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4e912146{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4e912fb0{width:4.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4e912fba{width:1.5in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4e912fbb{width:4.5in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4e912fc4{width:1.5in;background-color:transparent;vertical-align: top;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}reviewbigramsLove Love Love The Savoy If you are looking for a luxe hotel that isn't stuffy this is the place for you You feel like a millionaire even if you're not one and it's a great place to hang out if you fancy keeping off the streets of London for a while Classy decor wonderful food and cocktails and the staff are wonderful it is an absolute allrounder and if I could afford it I would probably live therelove lovelove loveclassy decordecor wonderfulwonderful foodabsolute allrounder "],["save.html", "1.8 Save", " 1.8 Save Save the cleaned data for other analyses like topic modeling and sentiment analysis. save(prepped_hotel, token, bigram, file = &quot;input/hotel_prepped.Rdata&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
